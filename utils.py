"""
å·¥å…·å‡½æ•°ï¼šPDFå¤„ç† + æ¨¡å‹æ¨ç† - Phase 2
"""
import base64
from pathlib import Path
from PIL import Image
import fitz  # PyMuPDF
from openai import OpenAI
import config
from io import BytesIO


def pdf_to_images(pdf_path):
    """PDF è½¬å›¾ç‰‡"""
    doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        mat = fitz.Matrix(config.PDF_DPI / 72, config.PDF_DPI / 72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    
    doc.close()
    return images


def resize_image_if_needed(image):
    """è°ƒæ•´å›¾åƒå¤§å°"""
    width, height = image.size
    pixels = width * height
    
    if pixels > config.IMAGE_MAX_PIXELS:
        scale = (config.IMAGE_MAX_PIXELS / pixels) ** 0.5
        new_width = int(width * scale)
        new_height = int(height * scale)
        image = image.resize((new_width, new_height), Image.LANCZOS)
        print(f"ğŸ“ Image resized: {width}x{height} -> {new_width}x{new_height}")
    
    return image


def image_to_base64(image):
    """å›¾ç‰‡è½¬ Base64"""
    if isinstance(image, (str, Path)):
        image = Image.open(image)
    
    image = resize_image_if_needed(image)
    
    buffer = BytesIO()
    image.save(buffer, format=config.IMAGE_FORMAT)
    return base64.b64encode(buffer.getvalue()).decode()


def infer_single_image(image, model_key, prompt, temperature, top_p, max_tokens):
    """
    å•å¼ å›¾ç‰‡æ¨ç†ï¼ˆæ”¯æŒåŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼‰
    
    Args:
        image: PIL.Image æˆ–æ–‡ä»¶è·¯å¾„
        model_key: æ¨¡å‹é…ç½®é”®ï¼ˆconfig.MODELS ä¸­çš„é”®ï¼‰
        prompt: æç¤ºè¯
        temperature: æ¸©åº¦å‚æ•°
        top_p: top_p å‚æ•°
        max_tokens: æœ€å¤§ token æ•°
    
    Returns:
        str: Markdown ç»“æœ
    """
    # è·å–æ¨¡å‹é…ç½®
    if model_key not in config.MODELS:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹: {model_key}")
    
    model_config = config.MODELS[model_key]
    
    # è½¬æ¢ä¸º Base64
    img_base64 = image_to_base64(image)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(
        api_key="dummy",
        base_url=model_config["api_base"],
        timeout=120.0
    )
    
    # è°ƒç”¨ API
    response = client.chat.completions.create(
        model=model_config["model_id"],
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_base64}"
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }],
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        extra_body={  # âœ… æ·»åŠ è¿™ä¸ª
        'repetition_penalty': 1.0,
        'top_k': 50,
        'skip_special_tokens': True,
        }
    )
    
    return response.choices[0].message.content


def process_document(file_path, model_key, prompt, temperature, top_p, max_tokens, progress=None):
    """
    å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒè‡ªå®šä¹‰å‚æ•°ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        model_key: æ¨¡å‹é”®
        prompt: æç¤ºè¯
        temperature: æ¸©åº¦
        top_p: top_p
        max_tokens: æœ€å¤§ tokens
        progress: Gradio Progress å¯¹è±¡
    
    Returns:
        tuple: (å›¾ç‰‡åˆ—è¡¨, Markdown ç»“æœ)
    """
    file_path = Path(file_path)
    
    # åˆ¤æ–­æ–‡ä»¶ç±»å‹
    if file_path.suffix.lower() == '.pdf':
        if progress is not None:
            progress(0, desc="Converting PDF...")
        images = pdf_to_images(file_path)
    else:
        images = [Image.open(file_path)]
    
    # é€é¡µæ¨ç†
    results = []
    total = len(images)
    
    for i, img in enumerate(images):
        if progress is not None:
            progress((i + 1) / total, desc=f"Processing page {i + 1}/{total}...")
        
        result = infer_single_image(
            img, 
            model_key, 
            prompt, 
            temperature, 
            top_p, 
            max_tokens
        )
        results.append(result)
    
    # åˆå¹¶ç»“æœ
    if len(results) > 1:
        markdown = "\n\n---\n\n".join([
            f"## Page {i + 1}\n\n{result}" 
            for i, result in enumerate(results)
        ])
    else:
        markdown = results[0]
    
    return images, markdown


def validate_file(file_path):
    """éªŒè¯æ–‡ä»¶"""
    if not file_path:
        return False, "è¯·ä¸Šä¼ æ–‡ä»¶"
    
    file_path = Path(file_path)
    
    if not file_path.exists():
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"
    
    if file_path.suffix.lower() not in config.ALLOWED_FILE_TYPES:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒï¼š{', '.join(config.ALLOWED_FILE_TYPES)}"
    
    size_mb = file_path.stat().st_size / (1024 * 1024)
    if size_mb > config.MAX_FILE_SIZE_MB:
        return False, f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{size_mb:.1f}MBï¼‰ï¼Œæœ€å¤§æ”¯æŒ {config.MAX_FILE_SIZE_MB}MB"
    
    return True, ""


def get_model_choices():
    """
    è·å–æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼ˆç”¨äº Gradio Dropdownï¼‰
    
    Returns:
        list: æ¨¡å‹æ˜¾ç¤ºåç§°åˆ—è¡¨
    """
    return [model["name"] for model in config.MODELS.values()]


def get_model_key_from_name(model_name):
    """
    ä»æ˜¾ç¤ºåç§°è·å–æ¨¡å‹é”®
    
    Args:
        model_name: æ¨¡å‹æ˜¾ç¤ºåç§°
    
    Returns:
        str: æ¨¡å‹é”®
    """
    for key, model in config.MODELS.items():
        if model["name"] == model_name:
            return key
    return config.DEFAULT_MODEL


def test_model_connection(model_key):
    """
    æµ‹è¯•æ¨¡å‹ API è¿æ¥
    
    Args:
        model_key: æ¨¡å‹é”®
    
    Returns:
        tuple: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
    """
    try:
        model_config = config.MODELS[model_key]
        client = OpenAI(
            api_key="dummy",
            base_url=model_config["api_base"],
            timeout=5.0
        )
        
        # ç®€å•æµ‹è¯•
        client.models.list()
        return True, f"âœ… {model_config['name']} è¿æ¥æ­£å¸¸"
    
    except Exception as e:
        return False, f"âŒ {model_config['name']} è¿æ¥å¤±è´¥: {str(e)}"