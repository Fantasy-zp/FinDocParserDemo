"""
å·¥å…·å‡½æ•°ï¼šPDFå¤„ç† + æ¨¡å‹æ¨ç† - Phase 3.2 æµå¼ç‰ˆæœ¬
"""
import base64
from pathlib import Path
from PIL import Image
import fitz  # PyMuPDF
from openai import OpenAI
import config
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from typing import Generator, Dict, Any, List, Tuple
from cache_manager import get_cache_manager
import requests
import json
import threading


def pdf_to_images(pdf_path):
    """PDF è½¬å›¾ç‰‡"""
    doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        mat = fitz.Matrix(config.PDF_DPI / 72, config.PDF_DPI / 72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    
    doc.close()
    return images


def resize_image_if_needed(image):
    """è°ƒæ•´å›¾åƒå¤§å°"""
    width, height = image.size
    pixels = width * height
    
    if pixels > config.IMAGE_MAX_PIXELS:
        scale = (config.IMAGE_MAX_PIXELS / pixels) ** 0.5
        new_width = int(width * scale)
        new_height = int(height * scale)
        image = image.resize((new_width, new_height), Image.LANCZOS)
    
    return image


def image_to_base64(image):
    """å›¾ç‰‡è½¬ Base64"""
    if isinstance(image, (str, Path)):
        image = Image.open(image)
    
    image = resize_image_if_needed(image)
    
    buffer = BytesIO()
    if image.mode in ('RGBA', 'LA', 'P'):
        image = image.convert('RGB')
    image.save(buffer, format='JPEG', quality=85)
    
    return base64.b64encode(buffer.getvalue()).decode()


def infer_single_image(image, model_key, prompt, temperature, top_p, max_tokens):
    """å•å¼ å›¾ç‰‡æ¨ç†"""
    if model_key not in config.MODELS:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹: {model_key}")
    
    model_config = config.MODELS[model_key]
    img_base64 = image_to_base64(image)
    
    client = OpenAI(
        api_key="dummy",
        base_url=model_config["api_base"],
        timeout=120.0
    )
    
    response = client.chat.completions.create(
        model=model_config["model_id"],
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}",
                        "detail": "high"
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }],
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        extra_body={
            'repetition_penalty': 1.0,
            'top_k': 50,
            'skip_special_tokens': True,
        }
    )
    # è·å–è¿”å›å†…å®¹
    result = response.choices[0].message.content

    # âœ… æ·»åŠ  JSON æ ¼å¼åˆ¤æ–­å’Œæå–
    result = extract_markdown_from_result(result)
    
    return result

# âœ… æ·»åŠ æ–°å‡½æ•°ï¼šæå– markdown å†…å®¹
def extract_markdown_from_result(result: str) -> str:
    """
    ä» API è¿”å›ç»“æœä¸­æå– markdown å†…å®¹ï¼ˆå®Œæ•´å¢å¼ºç‰ˆï¼‰
    
    æ”¯æŒï¼š
    1. å®Œæ•´ JSON â†’ json.loads è§£æ
    2. ä¸å®Œæ•´ JSON â†’ æ­£åˆ™æå–
    3. çº¯ Markdown â†’ ç›´æ¥è¿”å›
    """
    import json
    import re
    
    original_result = result
    result = result.strip()
    
    # å¿«é€Ÿæ’é™¤ï¼šæ˜æ˜¾ä¸æ˜¯ JSON
    if not result.startswith('{'):
        return original_result
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å« natural_text å­—æ®µ
    if '"natural_text"' not in result:
        print("â„¹ï¸  JSON æ ¼å¼ä½†ä¸åŒ…å« natural_text å­—æ®µ")
        return original_result
    
    # ============================================
    # å°è¯• 1ï¼šå®Œæ•´ JSON è§£æ
    # ============================================
    try:
        data = json.loads(result)
        
        if isinstance(data, dict) and 'natural_text' in data:
            markdown_text = data['natural_text']
            print(f"âœ… ä»å®Œæ•´ JSON æå– natural_text (é•¿åº¦: {len(markdown_text)} å­—ç¬¦)")
            return f"{markdown_text}\n\n<!-- RAW_OUTPUT_START\n{original_result}\nRAW_OUTPUT_END -->"
        else:
            print(f"âš ï¸  JSON è§£ææˆåŠŸä½†ç»“æ„ä¸ç¬¦åˆé¢„æœŸ")
            return original_result
            
    except json.JSONDecodeError as e:
        # ============================================
        # å°è¯• 2ï¼šä»ä¸å®Œæ•´ JSON ä¸­æ­£åˆ™æå–
        # ============================================
        print(f"âš ï¸  JSON ä¸å®Œæ•´ï¼Œå°è¯•æ­£åˆ™æå–...")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"   æœ€å 50 å­—ç¬¦: ...{result[-50:]}")
        
        # ç”¨æ­£åˆ™æå– natural_text çš„å€¼
        extracted = extract_natural_text_by_regex(result)
        
        if extracted:
            print(f"âš¡ æˆåŠŸä»ä¸å®Œæ•´ JSON ä¸­æå– {len(extracted)} å­—ç¬¦")
            
            # æ·»åŠ æˆªæ–­è­¦å‘Š
            # warning = "\n\n---\nâš ï¸ **è­¦å‘Š**ï¼šè¾“å‡ºè¢«æˆªæ–­ï¼ˆè¾¾åˆ° Max Tokens é™åˆ¶ï¼‰ï¼Œå†…å®¹å¯èƒ½ä¸å®Œæ•´ã€‚å»ºè®®å¢åŠ  Max Tokens å‚æ•°ã€‚"
            
            return f"{extracted}\n\n<!-- RAW_OUTPUT_START\n{original_result}\nRAW_OUTPUT_END -->"
        else:
            print(f"âŒ æ— æ³•ä»ä¸å®Œæ•´ JSON ä¸­æå– natural_text")
            return f"âš ï¸ **è§£æå¤±è´¥**ï¼šè¾“å‡ºè¢«æˆªæ–­ä¸”æ— æ³•æå–å†…å®¹ã€‚\n\n**å»ºè®®**ï¼š\n1. å¢åŠ  Max Tokens åˆ° 16384\n2. ç®€åŒ–æ–‡æ¡£æˆ–åˆ†é¡µå¤„ç†\n\n**åŸå§‹è¾“å‡º**ï¼š\n```\n{original_result[:500]}...\n```"


def extract_natural_text_by_regex(incomplete_json: str) -> str:
    """
    ç”¨æ­£åˆ™ä»ä¸å®Œæ•´çš„ JSON ä¸­æå– natural_text çš„å€¼
    
    Args:
        incomplete_json: ä¸å®Œæ•´çš„ JSON å­—ç¬¦ä¸²
    
    Returns:
        æå–çš„ markdown å†…å®¹ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
    """
    import re
    
    # åŒ¹é…æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§å°è¯•ï¼‰
    patterns = [
        # æ¨¡å¼ 1ï¼šå®Œæ•´çš„å€¼ï¼ˆå¸¦ç»“æŸå¼•å·å’Œé€—å·/å³æ‹¬å·ï¼‰
        r'"natural_text"\s*:\s*"((?:[^"\\]|\\.)*)"',
        
        # æ¨¡å¼ 2ï¼šä¸å®Œæ•´çš„å€¼ï¼ˆæ²¡æœ‰ç»“æŸå¼•å·ï¼Œç›´åˆ°å­—ç¬¦ä¸²æœ«å°¾ï¼‰
        r'"natural_text"\s*:\s*"((?:[^"\\]|\\.)*?)(?:$|")',
    ]
    
    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, incomplete_json, re.DOTALL)
        
        if match:
            content = match.group(1)
            
            # å¤„ç† JSON è½¬ä¹‰å­—ç¬¦
            content = unescape_json_string(content)
            
            print(f"   âœ… æ­£åˆ™æ¨¡å¼ {i} åŒ¹é…æˆåŠŸ")
            return content.strip()
    
    return ""


def unescape_json_string(s: str) -> str:
    """å¤„ç† JSON å­—ç¬¦ä¸²ä¸­çš„è½¬ä¹‰å­—ç¬¦"""
    # æŒ‰é¡ºåºå¤„ç†ï¼ˆé¡ºåºå¾ˆé‡è¦ï¼‰
    replacements = [
        ('\\n', '\n'),   # æ¢è¡Œ
        ('\\t', '\t'),   # åˆ¶è¡¨ç¬¦
        ('\\r', '\r'),   # å›è½¦
        ('\\"', '"'),    # å¼•å·
        ('\\/', '/'),    # æ–œæ 
        ('\\\\', '\\'),  # åæ–œæ ï¼ˆæœ€åå¤„ç†ï¼‰
    ]
    
    for old, new in replacements:
        s = s.replace(old, new)
    
    return s

# def extract_markdown_from_result(result: str) -> str:
#     """å¢å¼ºç‰ˆï¼šæ”¯æŒå¤šç§æå–ç­–ç•¥"""
#     import json
    
#     result = result.strip()
    
#     # ç­–ç•¥ 1ï¼šJSON æ ¼å¼
#     if result.startswith('{') and result.endswith('}'):
#         try:
#             data = json.loads(result)
            
#             if isinstance(data, dict):
#                 # ä¼˜å…ˆçº§ï¼šnatural_text > text > content > markdown
#                 for key in ['natural_text', 'text', 'content', 'markdown']:
#                     if key in data:
#                         print(f"âœ… ä» JSON æå–å­—æ®µ: {key}")
#                         return data[key]
#         except json.JSONDecodeError:
#             pass
    
#     # ç­–ç•¥ 2ï¼šMarkdown ä»£ç å—
#     if '```markdown' in result:
#         import re
#         match = re.search(r'```markdown\n(.*?)\n```', result, re.DOTALL)
#         if match:
#             print("âœ… ä» markdown ä»£ç å—æå–")
#             return match.group(1)
    
#     # é»˜è®¤ï¼šè¿”å›åŸå§‹ç»“æœ
#     return result

def process_single_page_with_index(idx, image, model_key, prompt, temperature, top_p, max_tokens):
    """å¤„ç†å•é¡µï¼ˆå¸¦ç´¢å¼•ï¼‰"""
    start_time = time.time()
    try:
        result = infer_single_image(image, model_key, prompt, temperature, top_p, max_tokens)
        elapsed = time.time() - start_time
        return (idx, result, elapsed, None)
    except Exception as e:
        elapsed = time.time() - start_time
        return (idx, None, elapsed, str(e))


# ============================================
# Phase 3.2: æµå¼å¤„ç†æ ¸å¿ƒå‡½æ•°
# ============================================

def process_images_streaming(
    images: List[Image.Image],
    model_key: str,
    prompt: str,
    temperature: float,
    top_p: float,
    max_tokens: int
) -> Generator[Dict[str, Any], None, None]:
    """
    æµå¼å¹¶è¡Œå¤„ç†å›¾ç‰‡ï¼ˆPhase 3.4 ä¼˜åŒ–ç‰ˆ - å•é¡µå®æ—¶åé¦ˆå¢å¼ºï¼‰
    
    å•é¡µå¤„ç†æ—¶ä¼šå®æ—¶æ›´æ–°å·²ç”¨æ—¶é—´
    """
    import threading
    
    total = len(images)
    completed_count = 0
    elapsed_times = []
    start_time = time.time()
    
    # å­˜å‚¨ç»“æœï¼ˆä¿æŒé¡ºåºï¼‰
    results = {}
    
    # å•é¡µç›´æ¥å¤„ç†ï¼ˆâœ… æ·»åŠ å®æ—¶è¿›åº¦æ›´æ–°ï¼‰
    if total < config.PARALLEL_MIN_PAGES:
        for idx, img in enumerate(images):
            # ç”¨äºçº¿ç¨‹é—´é€šä¿¡
            result_container = {"result": None, "elapsed": 0, "error": None, "done": False}
            
            # âœ… åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œæ¨ç†
            def inference_thread():
                page_start = time.time()
                try:
                    _, result, page_elapsed, error = process_single_page_with_index(
                        idx, img, model_key, prompt, temperature, top_p, max_tokens
                    )
                    result_container["result"] = result
                    result_container["elapsed"] = page_elapsed
                    result_container["error"] = error
                except Exception as e:
                    result_container["error"] = str(e)
                finally:
                    result_container["done"] = True
            
            # å¯åŠ¨æ¨ç†çº¿ç¨‹
            thread = threading.Thread(target=inference_thread, daemon=True)
            thread.start()
            
            # âœ… ä¸»çº¿ç¨‹å®šæœŸæ›´æ–°çŠ¶æ€ï¼ˆæ¯0.5ç§’ï¼‰
            page_start_time = time.time()
            while not result_container["done"]:
                elapsed = time.time() - page_start_time
                
                # æ¨¡æ‹Ÿè¿›åº¦ï¼ˆåŸºäºæ—¶é—´ä¼°ç®—ï¼‰
                # å‡è®¾å¹³å‡æ¯é¡µ 5-10 ç§’ï¼Œç”¨è„‰æåŠ¨ç”»
                pulse = int((elapsed * 2) % 20)  # 0-19 å¾ªç¯
                progress_bar = "â–ˆ" * pulse + "â–‘" * (20 - pulse)
                
                yield {
                    "page_num": idx + 1,
                    "total_pages": total,
                    "result": None,
                    "completed": completed_count,
                    "progress": 0,
                    "elapsed": elapsed,
                    "eta": 0,
                    "status": f"â³ æ­£åœ¨å¤„ç†ç¬¬ {idx + 1}/{total} é¡µ..."
                }
                
                time.sleep(0.5)  # æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡
            
            # âœ… ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join(timeout=1)
            
            # å¤„ç†ç»“æœ
            completed_count += 1
            elapsed_times.append(result_container["elapsed"])
            
            if result_container["error"] is None:
                results[idx] = result_container["result"]
            else:
                results[idx] = f"Error: {result_container['error']}"
            
            # âœ… è¿”å›å®ŒæˆçŠ¶æ€
            yield {
                "page_num": idx + 1,
                "total_pages": total,
                "result": results[idx],
                "completed": completed_count,
                "progress": 1.0,
                "elapsed": result_container["elapsed"],
                "eta": 0,
                "status": f"âœ… ç¬¬ {idx + 1}/{total} é¡µå®Œæˆ ({result_container['elapsed']:.1f}s)"
            }
        return
    
    # å¤šé¡µå¹¶è¡Œå¤„ç†ï¼ˆä¿æŒä¸å˜ï¼‰
    with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        future_to_idx = {
            executor.submit(
                process_single_page_with_index,
                idx, img, model_key, prompt, temperature, top_p, max_tokens
            ): idx
            for idx, img in enumerate(images)
        }
        
        for future in as_completed(future_to_idx):
            idx, result, page_elapsed, error = future.result()
            completed_count += 1
            elapsed_times.append(page_elapsed)
            
            results[idx] = result if error is None else f"Error on page {idx + 1}: {error}"
            
            avg_time = sum(elapsed_times) / len(elapsed_times)
            remaining = total - completed_count
            eta = avg_time * remaining
            total_elapsed = time.time() - start_time
            
            yield {
                "page_num": idx + 1,
                "total_pages": total,
                "result": results[idx],
                "completed": completed_count,
                "progress": completed_count / total,
                "elapsed": total_elapsed,
                "eta": eta,
                "status": f"âœ… ç¬¬ {idx + 1}/{total} é¡µå®Œæˆ ({page_elapsed:.1f}s, é¢„è®¡å‰©ä½™: {eta:.1f}s)"
            }

def merge_results_ordered(results: Dict[int, str], total: int) -> str:
    """
    æŒ‰é¡ºåºåˆå¹¶ç»“æœ
    
    Args:
        results: {é¡µç ç´¢å¼•: markdownç»“æœ}
        total: æ€»é¡µæ•°
    
    Returns:
        åˆå¹¶åçš„ markdown
    """
    ordered_results = []
    for i in range(total):
        if i in results:
            ordered_results.append(f"## Page {i + 1}\n\n{results[i]}")
        else:
            ordered_results.append(f"## Page {i + 1}\n\nâ³ Processing...")
    
    return "\n\n---\n\n".join(ordered_results)


def process_document_streaming(
    file_path: str,
    model_key: str,
    prompt: str,
    temperature: float,
    top_p: float,
    max_tokens: int
) -> Generator[Tuple[List[Image.Image], str, str], None, None]:
    """
    æµå¼å¤„ç†æ–‡æ¡£ï¼ˆPhase 3.2 ä¸»æ¥å£ï¼‰
    
    æ¯å®Œæˆä¸€é¡µå°±è¿”å›å½“å‰çŠ¶æ€
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        å…¶ä»–å‚æ•°: æ¨ç†å‚æ•°
    
    Yields:
        (images, status, markdown)
        - images: å·²å¤„ç†çš„å›¾ç‰‡åˆ—è¡¨
        - status: çŠ¶æ€æ–‡æœ¬
        - markdown: å½“å‰ç´¯ç§¯çš„ç»“æœ
    """
    file_path = Path(file_path)
    
    # åŠ è½½å›¾ç‰‡
    if file_path.suffix.lower() == '.pdf':
        images = pdf_to_images(file_path)
    else:
        images = [Image.open(file_path)]
    
    total = len(images)
    
    # åˆå§‹çŠ¶æ€
    yield (
        images,
        f"ğŸ“„ Loaded {total} page(s), starting processing...",
        ""
    )
    
    # æ”¶é›†æ‰€æœ‰ç»“æœ
    all_results = {}
    
    # æµå¼å¤„ç†
    for update in process_images_streaming(
        images, model_key, prompt, temperature, top_p, max_tokens
    ):
        page_idx = update["page_num"] - 1
        all_results[page_idx] = update["result"]
        
        # æ„å»ºçŠ¶æ€æ–‡æœ¬
        progress_bar = "â–ˆ" * int(update["progress"] * 20) + "â–‘" * (20 - int(update["progress"] * 20))
        status = f"""ğŸ”„ Processing: {update['completed']}/{update['total_pages']} pages

{progress_bar} {update['progress']*100:.1f}%

â±ï¸  Elapsed: {update['elapsed']:.1f}s
â° ETA: {update['eta']:.1f}s

{update['status']}"""
        
        # åˆå¹¶å½“å‰ç»“æœ
        if total == 1:
            markdown = all_results.get(0, "")
        else:
            markdown = merge_results_ordered(all_results, total)
        
        # âœ… è¿”å›å½“å‰çŠ¶æ€
        yield (images, status, markdown)
    
    # æœ€ç»ˆçŠ¶æ€
    final_markdown = merge_results_ordered(all_results, total) if total > 1 else all_results.get(0, "")
    
    yield (
        images,
        f"âœ… Completed! {total} page(s) processed successfully.",
        final_markdown
    )


# ============================================
# ä¿ç•™åŸæœ‰æ¥å£ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
# ============================================

def process_images_parallel(images, model_key, prompt, temperature, top_p, max_tokens, progress=None):
    """å¹¶è¡Œå¤„ç†ï¼ˆéæµå¼ï¼Œä¿ç•™å…¼å®¹ï¼‰"""
    total = len(images)
    
    if total < config.PARALLEL_MIN_PAGES:
        results = []
        for idx, img in enumerate(images):
            if progress is not None:
                progress((idx + 1) / total, desc=f"Processing page {idx + 1}/{total}")
            
            _, result, elapsed, error = process_single_page_with_index(
                idx, img, model_key, prompt, temperature, top_p, max_tokens
            )
            results.append(result if error is None else f"Error: {error}")
        return results
    
    results = [None] * total
    completed_count = 0
    total_time = 0
    
    with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        future_to_idx = {
            executor.submit(
                process_single_page_with_index,
                idx, img, model_key, prompt, temperature, top_p, max_tokens
            ): idx
            for idx, img in enumerate(images)
        }
        
        for future in as_completed(future_to_idx):
            idx, result, elapsed, error = future.result()
            completed_count += 1
            total_time += elapsed
            
            if error is None:
                results[idx] = result
            else:
                results[idx] = f"Error on page {idx + 1}: {error}"
            
            if progress is not None:
                avg_time = total_time / completed_count
                remaining = total - completed_count
                eta = avg_time * remaining
                progress(
                    completed_count / total,
                    desc=f"Completed {completed_count}/{total} pages (ETA: {eta:.1f}s)"
                )
    
    return results


def process_document(file_path, model_key, prompt, temperature, top_p, max_tokens, progress=None):
    """å¤„ç†æ–‡æ¡£ï¼ˆéæµå¼ï¼Œä¿ç•™å…¼å®¹ï¼‰"""
    file_path = Path(file_path)
    
    if file_path.suffix.lower() == '.pdf':
        if progress is not None:
            progress(0, desc="Converting PDF to images...")
        images = pdf_to_images(file_path)
    else:
        images = [Image.open(file_path)]
    
    if config.PARALLEL_ENABLED:
        results = process_images_parallel(
            images, model_key, prompt, temperature, top_p, max_tokens, progress
        )
    else:
        results = []
        for idx, img in enumerate(images):
            if progress is not None:
                progress((idx + 1) / len(images), desc=f"Processing page {idx + 1}/{len(images)}")
            result = infer_single_image(img, model_key, prompt, temperature, top_p, max_tokens)
            results.append(result)
    
    if len(results) > 1:
        markdown = "\n\n---\n\n".join([
            f"## Page {i + 1}\n\n{result}" 
            for i, result in enumerate(results)
        ])
    else:
        markdown = results[0]
    
    return images, markdown


def validate_file(file_path):
    """éªŒè¯æ–‡ä»¶"""
    if not file_path:
        return False, "è¯·ä¸Šä¼ æ–‡ä»¶"
    
    file_path = Path(file_path)
    
    if not file_path.exists():
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"
    
    if file_path.suffix.lower() not in config.ALLOWED_FILE_TYPES:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒï¼š{', '.join(config.ALLOWED_FILE_TYPES)}"
    
    size_mb = file_path.stat().st_size / (1024 * 1024)
    if size_mb > config.MAX_FILE_SIZE_MB:
        return False, f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{size_mb:.1f}MBï¼‰ï¼Œæœ€å¤§æ”¯æŒ {config.MAX_FILE_SIZE_MB}MB"
    
    return True, ""


def get_model_choices():
    """è·å–æ¨¡å‹é€‰æ‹©åˆ—è¡¨"""
    return [model["name"] for model in config.MODELS.values()]


def get_model_key_from_name(model_name):
    """ä»æ˜¾ç¤ºåç§°è·å–æ¨¡å‹é”®"""
    for key, model in config.MODELS.items():
        if model["name"] == model_name:
            return key
    return config.DEFAULT_MODEL


def test_model_connection(model_key):
    """æµ‹è¯•æ¨¡å‹ API è¿æ¥"""
    try:
        model_config = config.MODELS[model_key]
        client = OpenAI(
            api_key="dummy",
            base_url=model_config["api_base"],
            timeout=5.0
        )
        
        client.models.list()
        return True, f"âœ… {model_config['name']} è¿æ¥æ­£å¸¸"
    
    except Exception as e:
        return False, f"âŒ {model_config['name']} è¿æ¥å¤±è´¥: {str(e)}"

# ============================================
# Phase 3.3: ç¼“å­˜é…ç½®
# ============================================

def process_document_with_cache(
    file_path: str,
    model_key: str,
    prompt: str,
    temperature: float,
    top_p: float,
    max_tokens: int
) -> Tuple[List[Image.Image], str, bool]:
    """
    å¤„ç†æ–‡æ¡£ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Returns:
        (images, markdown, from_cache)
        - images: å›¾ç‰‡åˆ—è¡¨
        - markdown: ç»“æœ
        - from_cache: æ˜¯å¦æ¥è‡ªç¼“å­˜
    """
    if not config.CACHE_ENABLED:
        # ç¼“å­˜æœªå¯ç”¨ï¼Œç›´æ¥å¤„ç†
        images, markdown = process_document(
            file_path, model_key, prompt, temperature, top_p, max_tokens
        )
        return images, markdown, False
    
    # è·å–ç¼“å­˜ç®¡ç†å™¨
    cache_mgr = get_cache_manager()
    
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = cache_mgr.generate_cache_key(
        file_path, model_key, prompt, temperature, top_p, max_tokens
    )
    
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_result = cache_mgr.get(cache_key)
    
    if cached_result is not None:
        # ç¼“å­˜å‘½ä¸­
        # é‡æ–°åŠ è½½å›¾ç‰‡
        file_path = Path(file_path)
        if file_path.suffix.lower() == '.pdf':
            images = pdf_to_images(file_path)
        else:
            images = [Image.open(file_path)]
        
        markdown = cached_result["markdown"]
        return images, markdown, True
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæ¨ç†
    images, markdown = process_document(
        file_path, model_key, prompt, temperature, top_p, max_tokens
    )
    
    # ä¿å­˜åˆ°ç¼“å­˜
    result = {
        "markdown": markdown,
        "metadata": {
            "pages": len(images),
            "model": model_key,
            "timestamp": time.time()
        }
    }
    
    cache_mgr.set(
        cache_key,
        result,
        Path(file_path).name,
        model_key,
        temperature,
        top_p,
        max_tokens
    )
    
    return images, markdown, False

def is_valid_result(markdown: str) -> bool:
    """
    æ£€æŸ¥è§£æç»“æœæ˜¯å¦æœ‰æ•ˆï¼ˆä¸åŒ…å«é”™è¯¯ï¼‰
    
    è§„åˆ™ï¼š
    1. å†…å®¹ä¸èƒ½ä¸ºç©º
    2. å†…å®¹é•¿åº¦ >= 10 å­—ç¬¦
    3. ä¸åŒ…å«é”™è¯¯å…³é”®è¯
    4. é”™è¯¯æ•°é‡ä¸èƒ½è¿‡å¤š
    
    Args:
        markdown: è§£æå¾—åˆ°çš„ markdown å†…å®¹
    
    Returns:
        True: æœ‰æ•ˆç»“æœï¼Œå¯ä»¥ç¼“å­˜
        False: åŒ…å«é”™è¯¯ï¼Œä¸åº”ç¼“å­˜
    """
    # æ£€æŸ¥ 1ï¼šéç©º
    if not markdown:
        print("   âš ï¸  å†…å®¹ä¸ºç©º")
        return False
    
    # æ£€æŸ¥ 2ï¼šæœ€å°é•¿åº¦
    content = markdown.strip()
    if len(content) < 10:
        print(f"   âš ï¸  å†…å®¹è¿‡çŸ­ (åªæœ‰ {len(content)} å­—ç¬¦)")
        return False
    
    # æ£€æŸ¥ 3ï¼šé”™è¯¯å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    error_patterns = [
        "error:",
        "exception:",
        "failed:",
        "connection error",
        "timeout",
        "api error",
        "invalid response",
        "<!-- error:",  # HTML æ³¨é‡Šä¸­çš„é”™è¯¯
    ]
    
    content_lower = content.lower()
    
    for pattern in error_patterns:
        if pattern in content_lower:
            print(f"   âš ï¸  æ£€æµ‹åˆ°é”™è¯¯æ ‡è¯†: '{pattern}'")
            return False
    
    # æ£€æŸ¥ 4ï¼šé”™è¯¯å¯†åº¦ï¼ˆé˜²æ­¢å¤šé¡µéƒ½å¤±è´¥ï¼‰
    error_count = content_lower.count("error")
    total_length = len(content)
    
    if error_count > 0:
        error_density = error_count / (total_length / 1000)  # æ¯1000å­—ç¬¦çš„é”™è¯¯æ•°
        if error_density > 0.5:  # å¦‚æœæ¯1000å­—ç¬¦æœ‰è¶…è¿‡0.5ä¸ªerror
            print(f"   âš ï¸  é”™è¯¯å¯†åº¦è¿‡é«˜ (error å‡ºç° {error_count} æ¬¡)")
            return False
    
    # é€šè¿‡æ‰€æœ‰æ£€æŸ¥
    return True
# def is_valid_result(markdown: str) -> bool:
#     """å¢å¼ºç‰ˆï¼šæ›´ä¸¥æ ¼çš„éªŒè¯"""
#     if not markdown or len(markdown.strip()) < 10:
#         return False
    
#     content = markdown.strip()
#     content_lower = content.lower()
    
#     # 1. ä¸¥æ ¼çš„é”™è¯¯æ£€æŸ¥
#     strict_errors = [
#         "connection error",
#         "timeout",
#         "api error",
#         "authentication failed",
#         "rate limit exceeded",
#     ]
    
#     for error in strict_errors:
#         if error in content_lower:
#             return False
    
#     # 2. æ£€æŸ¥æ˜¯å¦æœ‰å®è´¨å†…å®¹ï¼ˆä¸åªæ˜¯é”™è¯¯ä¿¡æ¯ï¼‰
#     # è‡³å°‘åº”è¯¥åŒ…å«ä¸€äº›æ­£å¸¸çš„ markdown å…ƒç´ 
#     markdown_indicators = ["#", "##", "table", "```", "-", "*"]
#     has_markdown = any(indicator in content for indicator in markdown_indicators)
    
#     if not has_markdown and "error" in content_lower:
#         print("   âš ï¸  åªåŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œæ²¡æœ‰æœ‰æ•ˆå†…å®¹")
#         return False
    
#     # 3. æ£€æŸ¥ JSON æ ¼å¼çš„é”™è¯¯ï¼ˆå¦‚æœä½¿ç”¨äº† JSON æ ¼å¼ï¼‰
#     if content.startswith('{') and '"error"' in content_lower:
#         return False
    
#     return True

def extract_error_reason(markdown: str) -> str:
    """
    ä»é”™è¯¯å†…å®¹ä¸­æå–é”™è¯¯åŸå› 
    
    Args:
        markdown: åŒ…å«é”™è¯¯çš„ markdown å†…å®¹
    
    Returns:
        ç®€çŸ­çš„é”™è¯¯æè¿°
    """
    if not markdown:
        return "æœªçŸ¥é”™è¯¯"
    
    content_lower = markdown.lower()
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥é”™è¯¯ç±»å‹
    if "connection" in content_lower or "connect" in content_lower:
        return "ç½‘ç»œè¿æ¥å¤±è´¥"
    elif "timeout" in content_lower or "timed out" in content_lower:
        return "è¯·æ±‚è¶…æ—¶"
    elif "authentication" in content_lower or "unauthorized" in content_lower:
        return "è®¤è¯å¤±è´¥"
    elif "rate limit" in content_lower or "too many requests" in content_lower:
        return "è¯·æ±‚é¢‘ç‡è¶…é™"
    elif "api error" in content_lower or "api_error" in content_lower:
        return "API æœåŠ¡é”™è¯¯"
    elif "invalid" in content_lower:
        return "æ— æ•ˆçš„è¯·æ±‚"
    elif "not found" in content_lower or "404" in content_lower:
        return "API åœ°å€é”™è¯¯"
    elif "server error" in content_lower or "500" in content_lower:
        return "æœåŠ¡å™¨é”™è¯¯"
    else:
        # å°è¯•æå– Error: åé¢çš„å†…å®¹
        if "error:" in content_lower:
            try:
                error_start = content_lower.index("error:") + 6
                error_msg = markdown[error_start:error_start + 50].strip()
                # å–ç¬¬ä¸€è¡Œæˆ–å‰30ä¸ªå­—ç¬¦
                error_msg = error_msg.split('\n')[0][:30]
                return error_msg if error_msg else "è§£æé”™è¯¯"
            except:
                pass
        
        return "è§£æé”™è¯¯"

def process_document_streaming_with_cache(
    file_path: str,
    model_key: str,
    prompt: str,
    temperature: float,
    top_p: float,
    max_tokens: int
) -> Generator[Tuple[List[Image.Image], str, str, bool], None, None]:
    """
    æµå¼å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒå¤šç§æ¨¡å‹ç±»å‹ - Phase 3.5ï¼‰
    
    Yields:
        (images, status, markdown, from_cache)
    """
    model_info = config.MODELS.get(model_key)
    if not model_info:
        yield (None, f"âŒ æœªçŸ¥æ¨¡å‹: {model_key}", "", False)
        return
    
    model_type = model_info.get("type", "openai")
    
    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
    if model_type == "custom":
        # âœ… è‡ªå®šä¹‰ APIï¼ˆè·¨é¡µåˆå¹¶æ¨¡å‹ï¼‰
        yield from process_with_custom_model(file_path, model_key)
        return

    # ============================================
    # åŸæœ‰ä»£ç ï¼ˆOpenAI å…¼å®¹æ¨¡å‹ï¼‰
    # ============================================
    if not config.CACHE_ENABLED:
        for images, status, markdown in process_document_streaming(
            file_path, model_key, prompt, temperature, top_p, max_tokens
        ):
            yield images, status, markdown, False
        return
    
    cache_mgr = get_cache_manager()
    cache_key = cache_mgr.generate_cache_key(
        file_path, model_key, prompt, temperature, top_p, max_tokens
    )
    
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_result = cache_mgr.get(cache_key)
    
    if cached_result is not None:
        # ç¼“å­˜å‘½ä¸­
        file_path_obj = Path(file_path)
        if file_path_obj.suffix.lower() == '.pdf':
            images = pdf_to_images(file_path_obj)
        else:
            images = [Image.open(file_path_obj)]
        
        markdown = cached_result["markdown"]
        pages = cached_result["metadata"]["pages"]
        
        status = f"""âš¡ ä»ç¼“å­˜åŠ è½½ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ é¡µæ•°: {pages} é¡µ
ğŸ”¥ å“åº”æ—¶é—´: <0.1s
ğŸ’¾ ç¼“å­˜å‘½ä¸­ï¼"""
        
        yield images, status, markdown, True
        return
    
    # ç¼“å­˜æœªå‘½ä¸­ - æ‰§è¡Œæµå¼å¤„ç†
    file_path_obj = Path(file_path)
    
    if file_path_obj.suffix.lower() == '.pdf':
        images = pdf_to_images(file_path_obj)
    else:
        images = [Image.open(file_path_obj)]
    
    total = len(images)
    start_time = time.time()
    
    # åˆå§‹çŠ¶æ€
    initial_status = f"ğŸ“„ å·²åŠ è½½ {total} é¡µï¼Œå¼€å§‹å¤„ç†..."
    yield (images, initial_status, "", False)
    
    # æ”¶é›†æ‰€æœ‰ç»“æœ
    all_results = {}
    
    # æµå¼å¤„ç†
    for update in process_images_streaming(
        images, model_key, prompt, temperature, top_p, max_tokens
    ):
        page_idx = update["page_num"] - 1
        
        if update["result"] is not None:
            all_results[page_idx] = update["result"]
        
        # æ„å»ºçŠ¶æ€æ–‡æœ¬
        if total == 1:
            # å•é¡µçš„çŠ¶æ€æ˜¾ç¤º
            if update["completed"] == 0:
                # å¤„ç†ä¸­ï¼ˆå®æ—¶æ›´æ–°æ—¶é—´ï¼‰
                pulse = int((update["elapsed"] * 2) % 20)
                progress_bar = "â–ˆ" * pulse + "â–‘" * (20 - pulse)
                
                status = f"""â³ æ­£åœ¨å¤„ç†...

{progress_bar}

â±ï¸  å·²ç”¨æ—¶é—´: {update['elapsed']:.1f}s

{update['status']}"""
            else:
                # å®Œæˆ
                progress_bar = "â–ˆ" * 20
                status = f"""âœ… å¤„ç†å®Œæˆï¼

{progress_bar} 100%

â±ï¸  å¤„ç†æ—¶é—´: {update['elapsed']:.1f}s

{update['status']}"""
        else:
            # å¤šé¡µçš„çŠ¶æ€æ˜¾ç¤º
            progress_bar = "â–ˆ" * int(update["progress"] * 20) + "â–‘" * (20 - int(update["progress"] * 20))
            status = f"""ğŸ”„ å¤„ç†ä¸­: {update['completed']}/{update['total_pages']} é¡µ

{progress_bar} {update['progress']*100:.1f}%

â±ï¸  å·²ç”¨æ—¶é—´: {update['elapsed']:.1f}s
â° é¢„è®¡å‰©ä½™: {update['eta']:.1f}s

{update['status']}"""
        
        # åˆå¹¶å½“å‰ç»“æœ
        if total == 1:
            if 0 in all_results:
                markdown = all_results[0]
            else:
                markdown = "â³ æ­£åœ¨å¤„ç†ä¸­..."
        else:
            markdown = merge_results_ordered(all_results, total)
        
        yield (images, status, markdown, False)
    
    # ============================================
    # å¤„ç†å®Œæˆ - æ„å»ºæœ€ç»ˆçŠ¶æ€ï¼ˆè¯¦ç»†é”™è¯¯ç‰ˆï¼‰
    # ============================================
    final_markdown = merge_results_ordered(all_results, total) if total > 1 else all_results.get(0, "")
    total_elapsed = time.time() - start_time
    
    # âœ… éªŒè¯ç»“æœæ˜¯å¦æœ‰æ•ˆ
    is_valid = is_valid_result(final_markdown) if final_markdown else False
    
    # âœ… æ ¹æ®éªŒè¯ç»“æœæ„å»ºä¸åŒçš„çŠ¶æ€ä¿¡æ¯
    if is_valid:
        # ========== æˆåŠŸæƒ…å†µ ==========
        if total == 1:
            final_status = f"""âœ… è§£æå®Œæˆï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ é¡µæ•°: 1 é¡µ
â±ï¸  å¤„ç†æ—¶é—´: {total_elapsed:.1f}s
ğŸ’¾ å·²ä¿å­˜åˆ°ç¼“å­˜"""
        else:
            final_status = f"""âœ… è§£æå®Œæˆï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
â±ï¸  æ€»è€—æ—¶: {total_elapsed:.1f}s
ğŸ’¾ å·²ä¿å­˜åˆ°ç¼“å­˜"""
        
        # ä¿å­˜åˆ°ç¼“å­˜
        if images is not None:
            result = {
                "markdown": final_markdown,
                "metadata": {
                    "pages": len(images),
                    "model": model_key,
                    "timestamp": time.time()
                }
            }
            
            cache_mgr.set(
                cache_key,
                result,
                file_path_obj.name,
                model_key,
                temperature,
                top_p,
                max_tokens
            )
            print(f"âœ… æœ‰æ•ˆç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜")
    else:
        # ========== å¤±è´¥æƒ…å†µï¼ˆè¯¦ç»†é”™è¯¯æç¤ºï¼‰==========
        error_reason = extract_error_reason(final_markdown)
        
        if total == 1:
            final_status = f"""âŒ è§£æå¤±è´¥ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ é¡µæ•°: 1 é¡µ
â±ï¸  å¤„ç†æ—¶é—´: {total_elapsed:.1f}s
âš ï¸ é”™è¯¯åŸå› : {error_reason}
ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ›´æ¢æ¨¡å‹"""
        else:
            final_status = f"""âŒ è§£æå¤±è´¥ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
â±ï¸  æ€»è€—æ—¶: {total_elapsed:.1f}s
âš ï¸ é”™è¯¯åŸå› : {error_reason}
ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ›´æ¢æ¨¡å‹"""
        
        print(f"âš ï¸  è§£æå¤±è´¥: {error_reason}ï¼Œè·³è¿‡ç¼“å­˜")
    
    # è¿”å›æœ€ç»ˆç»“æœ
    yield (images, final_status, final_markdown, False)


def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ï¼ˆä¾›ç•Œé¢è°ƒç”¨ï¼‰"""
    if not config.CACHE_ENABLED:
        return "Cache disabled"
    
    cache_mgr = get_cache_manager()
    stats = cache_mgr.get_stats()
    
    return f"""ğŸ“Š Cache Statistics:
    
ğŸ’¾ Memory: {stats['memory_cache_size']} entries
ğŸ’½ Disk: {stats['disk_cache_count']} entries ({stats['disk_cache_size_mb']:.1f}MB)

ğŸ“ˆ Performance:
  Total requests: {stats['total_requests']}
  Memory hits: {stats['memory_hits']} âš¡
  Disk hits: {stats['disk_hits']} ğŸ’¾
  Misses: {stats['misses']} âŒ
  
ğŸ¯ Hit rate: {stats['hit_rate']}"""


def clear_cache():
    """æ¸…ç©ºç¼“å­˜ï¼ˆä¾›ç•Œé¢è°ƒç”¨ï¼‰"""
    if not config.CACHE_ENABLED:
        return "Cache disabled"
    
    cache_mgr = get_cache_manager()
    cache_mgr.clear_all()
    return "âœ… Cache cleared successfully!"

# ============================================
# Phase 3.5: è‡ªå®šä¹‰æ¨¡å‹æ”¯æŒï¼ˆè·¨é¡µåˆå¹¶ï¼‰
# ============================================

import json

def infer_with_custom_api(
    pdf_path: str,  # è™½ç„¶å« pdf_pathï¼Œä½†ä¹Ÿæ”¯æŒå›¾ç‰‡
    api_base: str,
    timeout: int = 300
) -> str:
    """
    è°ƒç”¨è‡ªå®šä¹‰ API è¿›è¡Œæ–‡æ¡£è§£æï¼ˆæ”¯æŒ PDF å’Œå›¾ç‰‡ï¼‰
    
    Args:
        pdf_path: æ–‡ä»¶è·¯å¾„ï¼ˆPDF æˆ–å›¾ç‰‡ï¼‰
        api_base: API åœ°å€ï¼ˆå¦‚ http://127.0.0.1:8002ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        è§£æç»“æœï¼ˆmarkdown + éšè—çš„åŸå§‹ JSONï¼‰
    """
    try:
        parse_url = f"{api_base}/parse"
        pdf_file = Path(pdf_path)
        
        if not pdf_file.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        # âœ… ä¿®æ”¹ 3ï¼šæ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½® MIME type
        suffix = pdf_file.suffix.lower()
        mime_types = {
            '.pdf': 'application/pdf',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg'
        }
        mime_type = mime_types.get(suffix, 'application/octet-stream')
        
        print(f"ğŸ“¤ ä¸Šä¼ æ–‡ä»¶åˆ°è·¨é¡µåˆå¹¶ API: {parse_url}")
        print(f"   æ–‡ä»¶: {pdf_file.name} ({pdf_file.stat().st_size / 1024:.1f}KB)")
        print(f"   ç±»å‹: {mime_type}")  # âœ… æ˜¾ç¤ºæ–‡ä»¶ç±»å‹
        
        # å‘é€è¯·æ±‚
        with open(pdf_file, 'rb') as f:
            files = {'file': (pdf_file.name, f, mime_type)}  # âœ… ä½¿ç”¨æ­£ç¡®çš„ MIME type
            response = requests.post(parse_url, files=files, timeout=timeout)
        
        # æ£€æŸ¥å“åº”
        response.raise_for_status()
        
        # è§£æ JSON å“åº”
        result = response.json()
        
        # ä¿å­˜åŸå§‹ JSON
        original_json = json.dumps(result, ensure_ascii=False, indent=2)
        
        # æ ¹æ®å®é™…è¿”å›æ ¼å¼æå–å†…å®¹
        if result.get('success') and 'result' in result:
            document_text = result['result'].get('document_text')
            num_pages = result['result'].get('num_pages', 0)
            
            if document_text:
                print(f"âœ… è·¨é¡µæ¨¡å‹è§£æå®Œæˆ")
                print(f"   é¡µæ•°: {num_pages}")
                print(f"   å†…å®¹é•¿åº¦: {len(document_text)} å­—ç¬¦")
                print(f"   åŸå§‹ JSON é•¿åº¦: {len(original_json)} å­—ç¬¦")
                
                combined = f"{document_text}\n\n<!-- RAW_OUTPUT_START\n{original_json}\nRAW_OUTPUT_END -->"
                return combined
            else:
                error_msg = "API è¿”å›çš„ document_text ä¸ºç©º"
                print(f"âš ï¸  {error_msg}")
                return f"<!-- Error: {error_msg} -->\n\n<!-- RAW_OUTPUT_START\n{original_json}\nRAW_OUTPUT_END -->"
        else:
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"âŒ API è¿”å›å¤±è´¥: {error_msg}")
            return f"<!-- Error: {error_msg} -->\n\n<!-- RAW_OUTPUT_START\n{original_json}\nRAW_OUTPUT_END -->"
        
    except requests.exceptions.Timeout:
        error_msg = f"è¯·æ±‚è¶…æ—¶ï¼ˆè¶…è¿‡ {timeout} ç§’ï¼‰"
        print(f"âš ï¸  {error_msg}")
        return f"<!-- Error: {error_msg} -->"
        
    except requests.exceptions.ConnectionError as e:
        error_msg = f"è¿æ¥å¤±è´¥ - {str(e)}"
        print(f"âš ï¸  {error_msg}")
        return f"<!-- Error: {error_msg} -->"
        
    except Exception as e:
        error_msg = f"è§£æå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        import traceback
        traceback.print_exc()
        return f"<!-- Error: {error_msg} -->"


def check_custom_api_health(api_base: str) -> bool:
    """
    æ£€æŸ¥è‡ªå®šä¹‰ API å¥åº·çŠ¶æ€
    
    Args:
        api_base: API åœ°å€
    
    Returns:
        True: å¥åº·ï¼ŒFalse: ä¸å¯ç”¨
    """
    try:
        health_url = f"{api_base}/health"
        response = requests.get(health_url, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'ok':
                print(f"âœ… è·¨é¡µæ¨¡å‹ API å¥åº·: {api_base}")
                return True
            else:
                print(f"âš ï¸  API çŠ¶æ€å¼‚å¸¸: {data}")
                return False
        else:
            print(f"âš ï¸  API è¿”å›çŠ¶æ€ç : {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ API å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False


def process_with_custom_model(
    file_path: str,
    model_key: str
) -> Generator[Tuple[List[Image.Image], str, str, bool], None, None]:
    """ä½¿ç”¨è‡ªå®šä¹‰ API å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒ PDF å’Œå›¾ç‰‡ï¼‰"""
    file_path_obj = Path(file_path)
    model_info = config.MODELS[model_key]
    
    # ============================================
    # 1. æ£€æŸ¥ç¼“å­˜
    # ============================================
    if config.CACHE_ENABLED:
        cache_mgr = get_cache_manager()
        cache_key = cache_mgr.generate_cache_key(
            file_path, model_key, "", 0, 0, 0
        )
        
        cached_result = cache_mgr.get(cache_key)
        if cached_result is not None:
            # ç¼“å­˜å‘½ä¸­
            try:
                # âœ… ä¿®æ”¹ 1ï¼šæ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½é¢„è§ˆ
                if file_path_obj.suffix.lower() == '.pdf':
                    images = pdf_to_images(file_path_obj)
                else:
                    images = [Image.open(file_path_obj)]
            except Exception as e:
                yield (None, f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}", "", False)
                return
            
            markdown = cached_result["markdown"]
            pages = cached_result["metadata"]["pages"]
            
            status = f"""âš¡ ä»ç¼“å­˜åŠ è½½ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ é¡µæ•°: {pages} é¡µ
ğŸ”¥ å“åº”æ—¶é—´: <0.1s
ğŸ’¾ ç¼“å­˜å‘½ä¸­ï¼"""
            
            yield images, status, markdown, True
            return
    
    # ============================================
    # 2. è½¬æ¢æ–‡ä»¶ä¸ºé¢„è§ˆå›¾ç‰‡
    # ============================================
    try:
        # âœ… ä¿®æ”¹ 2ï¼šæ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½é¢„è§ˆ
        if file_path_obj.suffix.lower() == '.pdf':
            images = pdf_to_images(file_path_obj)
        else:
            images = [Image.open(file_path_obj)]
    except Exception as e:
        yield (None, f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}", "", False)
        return
    
    total = len(images)
    start_time = time.time()
    
    # åˆå§‹çŠ¶æ€
    initial_status = f"""ğŸ“„ å·²åŠ è½½ {total} é¡µæ–‡æ¡£

â³ æ­£åœ¨è§£ææ•´ä¸ªæ–‡æ¡£ï¼ˆæ”¯æŒè·¨é¡µå†…å®¹è‡ªåŠ¨åˆå¹¶ï¼‰...

ğŸ’¡ æç¤ºï¼šæ­¤æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†è·¨é¡µå†…å®¹ï¼Œæ— éœ€é€é¡µè§£æ"""
    
    yield (images, initial_status, "", False)
    
    # ============================================
    # 3. å¸¦å¿ƒè·³çš„ API è°ƒç”¨ï¼ˆä¿æŒä¸å˜ï¼‰
    # ============================================
    result_container = {
        "done": False,
        "result": None,
        "error": None
    }
    
    def api_call_thread():
        try:
            result_container["result"] = infer_with_custom_api(
                file_path, 
                model_info["api_base"]
            )
        except Exception as e:
            result_container["error"] = str(e)
        finally:
            result_container["done"] = True
    
    thread = threading.Thread(target=api_call_thread, daemon=True)
    thread.start()
    
    heartbeat_interval = 1.0
    
    while not result_container["done"]:
        current_time = time.time()
        elapsed = current_time - start_time
        
        pulse_position = int((elapsed / heartbeat_interval) % 20)
        progress_bar = "â–ˆ" * pulse_position + "â–‘" * (20 - pulse_position)
        
        if elapsed < 10:
            hint = "ğŸ” æ­£åœ¨åˆ†ææ–‡æ¡£ç»“æ„..."
        elif elapsed < 20:
            hint = "ğŸ“Š æ­£åœ¨è¯†åˆ«æ–‡æœ¬å’Œè¡¨æ ¼..."
        elif elapsed < 30:
            hint = "ğŸ”— æ­£åœ¨åˆå¹¶è·¨é¡µå†…å®¹..."
        elif elapsed < 45:
            hint = "âœ¨ æ­£åœ¨ä¼˜åŒ–è¾“å‡ºæ ¼å¼..."
        else:
            hint = "â³ å¤æ‚æ–‡æ¡£éœ€è¦æ›´å¤šæ—¶é—´ï¼Œè¯·ç¨å€™..."
        
        status = f"""â³ æ­£åœ¨è§£ææ•´ä¸ªæ–‡æ¡£...

{progress_bar}

â±ï¸  å·²ç”¨æ—¶é—´: {elapsed:.1f}s
ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
{hint}"""
        
        yield (images, status, "", False)
        time.sleep(heartbeat_interval)
    
    # ============================================
    # 4. å¤„ç†ç»“æœï¼ˆä¿æŒä¸å˜ï¼‰
    # ============================================
    elapsed = time.time() - start_time
    
    if result_container["error"]:
        error_status = f"""âŒ è§£æå¤±è´¥ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
â±ï¸  å¤„ç†æ—¶é—´: {elapsed:.1f}s
âš ï¸  é”™è¯¯åŸå› : {result_container['error']}

ğŸ’¡ å»ºè®®: 
  1. æ£€æŸ¥ API æœåŠ¡çŠ¶æ€
  2. ç¡®è®¤æ–‡æ¡£æ ¼å¼æ­£ç¡®
  3. æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯"""
        
        yield (images, error_status, "", False)
        return
    
    markdown = result_container["result"]
    is_valid = is_valid_result(markdown) if markdown else False
    
    if is_valid:
        final_status = f"""âœ… è§£æå®Œæˆï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
â±ï¸  å¤„ç†æ—¶é—´: {elapsed:.1f}s
ğŸ’¾ å·²ä¿å­˜åˆ°ç¼“å­˜"""
        
        if config.CACHE_ENABLED:
            result = {
                "markdown": markdown,
                "metadata": {
                    "pages": total,
                    "model": model_key,
                    "timestamp": time.time()
                }
            }
            cache_mgr.set(
                cache_key, result, file_path_obj.name,
                model_key, 0, 0, 0
            )
            print(f"âœ… æœ‰æ•ˆç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜")
        
    else:
        error_reason = extract_error_reason(markdown)
        final_status = f"""âŒ è§£æå¤±è´¥ï¼

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

ğŸ“„ æ€»é¡µæ•°: {total} é¡µ
â±ï¸  å¤„ç†æ—¶é—´: {elapsed:.1f}s
âš ï¸  é”™è¯¯åŸå› : {error_reason}
ğŸ’¡ å»ºè®®: 
  1. æ£€æŸ¥ API æœåŠ¡çŠ¶æ€
  2. ç¡®è®¤æ–‡æ¡£æ ¼å¼æ­£ç¡®
  3. æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯"""
        
        print(f"âš ï¸  è§£æå¤±è´¥: {error_reason}")
    
    yield (images, final_status, markdown, False)