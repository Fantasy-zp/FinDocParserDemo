"""
å·¥å…·å‡½æ•°ï¼šPDFå¤„ç† + æ¨¡å‹æ¨ç† - Phase 3.1 å¹¶è¡Œç‰ˆæœ¬
"""
import base64
from pathlib import Path
from PIL import Image
import fitz  # PyMuPDF
from openai import OpenAI
import config
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


def pdf_to_images(pdf_path):
    """PDF è½¬å›¾ç‰‡"""
    doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        mat = fitz.Matrix(config.PDF_DPI / 72, config.PDF_DPI / 72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    
    doc.close()
    return images


def resize_image_if_needed(image):
    """è°ƒæ•´å›¾åƒå¤§å°"""
    width, height = image.size
    pixels = width * height
    
    if pixels > config.IMAGE_MAX_PIXELS:
        scale = (config.IMAGE_MAX_PIXELS / pixels) ** 0.5
        new_width = int(width * scale)
        new_height = int(height * scale)
        image = image.resize((new_width, new_height), Image.LANCZOS)
        print(f"ğŸ“ Image resized: {width}x{height} -> {new_width}x{new_height}")
    
    return image


def image_to_base64(image):
    """å›¾ç‰‡è½¬ Base64"""
    if isinstance(image, (str, Path)):
        image = Image.open(image)
    
    image = resize_image_if_needed(image)
    
    buffer = BytesIO()
    # ä½¿ç”¨ JPEG å‹ç¼©ä»¥å‡å°ä¼ è¾“å¤§å°
    if image.mode in ('RGBA', 'LA', 'P'):
        image = image.convert('RGB')
    image.save(buffer, format='JPEG', quality=85)
    
    return base64.b64encode(buffer.getvalue()).decode()


def infer_single_image(image, model_key, prompt, temperature, top_p, max_tokens):
    """
    å•å¼ å›¾ç‰‡æ¨ç†
    
    Args:
        image: PIL.Image æˆ–æ–‡ä»¶è·¯å¾„
        model_key: æ¨¡å‹é…ç½®é”®
        prompt: æç¤ºè¯
        temperature: æ¸©åº¦å‚æ•°
        top_p: top_p å‚æ•°
        max_tokens: æœ€å¤§ token æ•°
    
    Returns:
        str: Markdown ç»“æœ
    """
    # è·å–æ¨¡å‹é…ç½®
    if model_key not in config.MODELS:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹: {model_key}")
    
    model_config = config.MODELS[model_key]
    
    # è½¬æ¢ä¸º Base64
    img_base64 = image_to_base64(image)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(
        api_key="dummy",
        base_url=model_config["api_base"],
        timeout=120.0
    )
    
    # è°ƒç”¨ API
    response = client.chat.completions.create(
        model=model_config["model_id"],
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}"
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }],
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        extra_body={
            'repetition_penalty': 1.0,
            'top_k': 50,
            'skip_special_tokens': True,
        }
    )
    
    return response.choices[0].message.content


# ============================================
# Phase 3.1: å¹¶è¡Œå¤„ç†æ ¸å¿ƒå‡½æ•°
# ============================================

def process_single_page_with_index(idx, image, model_key, prompt, temperature, top_p, max_tokens):
    """
    å¤„ç†å•é¡µï¼ˆå¸¦ç´¢å¼•ï¼‰- ä¾›å¹¶è¡Œè°ƒç”¨
    
    Args:
        idx: é¡µç ç´¢å¼•
        image: å›¾åƒ
        å…¶ä»–å‚æ•°åŒ infer_single_image
    
    Returns:
        tuple: (idx, result, elapsed_time)
    """
    start_time = time.time()
    try:
        result = infer_single_image(image, model_key, prompt, temperature, top_p, max_tokens)
        elapsed = time.time() - start_time
        print(f"âœ… Page {idx + 1} completed in {elapsed:.2f}s")
        return (idx, result, elapsed, None)
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"âŒ Page {idx + 1} failed in {elapsed:.2f}s: {str(e)}")
        return (idx, None, elapsed, str(e))


def process_images_parallel(images, model_key, prompt, temperature, top_p, max_tokens, progress=None):
    """
    å¹¶è¡Œå¤„ç†å¤šå¼ å›¾ç‰‡ï¼ˆPhase 3.1 æ ¸å¿ƒï¼‰
    
    Args:
        images: å›¾ç‰‡åˆ—è¡¨
        å…¶ä»–å‚æ•°åŒä¸Š
        progress: Gradio Progress å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        list: æŒ‰é¡ºåºçš„æ¨ç†ç»“æœåˆ—è¡¨
    """
    total = len(images)
    
    # å•é¡µç›´æ¥å¤„ç†ï¼Œä¸å¯ç”¨å¹¶è¡Œ
    if total < config.PARALLEL_MIN_PAGES:
        print(f"ğŸ“„ Single page, using sequential processing")
        results = []
        for idx, img in enumerate(images):
            if progress is not None:
                progress((idx + 1) / total, desc=f"Processing page {idx + 1}/{total}")
            
            _, result, elapsed, error = process_single_page_with_index(
                idx, img, model_key, prompt, temperature, top_p, max_tokens
            )
            results.append(result if error is None else f"Error: {error}")
        return results
    
    # å¤šé¡µå¹¶è¡Œå¤„ç†
    print(f"ğŸš€ Parallel processing with {config.MAX_WORKERS} workers")
    
    # åˆå§‹åŒ–ç»“æœæ•°ç»„ï¼ˆä¿æŒé¡ºåºï¼‰
    results = [None] * total
    completed_count = 0
    total_time = 0
    
    # ä½¿ç”¨çº¿ç¨‹æ± 
    with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_idx = {
            executor.submit(
                process_single_page_with_index,
                idx, img, model_key, prompt, temperature, top_p, max_tokens
            ): idx
            for idx, img in enumerate(images)
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_idx):
            idx, result, elapsed, error = future.result()
            completed_count += 1
            total_time += elapsed
            
            # ä¿å­˜ç»“æœ
            if error is None:
                results[idx] = result
            else:
                results[idx] = f"Error on page {idx + 1}: {error}"
            
            # æ›´æ–°è¿›åº¦
            if progress is not None:
                avg_time = total_time / completed_count
                remaining = total - completed_count
                eta = avg_time * remaining
                progress(
                    completed_count / total,
                    desc=f"Completed {completed_count}/{total} pages (ETA: {eta:.1f}s)"
                )
    
    # ç»Ÿè®¡ä¿¡æ¯
    avg_time = total_time / total
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Parallel Processing Statistics:")
    print(f"  Total pages: {total}")
    print(f"  Total time: {total_time:.2f}s")
    print(f"  Avg time per page: {avg_time:.2f}s")
    print(f"  Workers used: {config.MAX_WORKERS}")
    print(f"{'='*60}\n")
    
    return results


def process_document(file_path, model_key, prompt, temperature, top_p, max_tokens, progress=None):
    """
    å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        model_key: æ¨¡å‹é”®
        prompt: æç¤ºè¯
        temperature: æ¸©åº¦
        top_p: top_p
        max_tokens: æœ€å¤§ tokens
        progress: Gradio Progress å¯¹è±¡
    
    Returns:
        tuple: (å›¾ç‰‡åˆ—è¡¨, Markdown ç»“æœ)
    """
    file_path = Path(file_path)
    
    # åˆ¤æ–­æ–‡ä»¶ç±»å‹
    if file_path.suffix.lower() == '.pdf':
        if progress is not None:
            progress(0, desc="Converting PDF to images...")
        images = pdf_to_images(file_path)
        print(f"ğŸ“„ PDF converted: {len(images)} pages")
    else:
        images = [Image.open(file_path)]
        print(f"ğŸ–¼ï¸  Single image loaded")
    
    # âœ… ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if config.PARALLEL_ENABLED:
        results = process_images_parallel(
            images, model_key, prompt, temperature, top_p, max_tokens, progress
        )
    else:
        # ä¸²è¡Œå¤„ç†ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨ï¼‰
        results = []
        for idx, img in enumerate(images):
            if progress is not None:
                progress((idx + 1) / len(images), desc=f"Processing page {idx + 1}/{len(images)}")
            result = infer_single_image(img, model_key, prompt, temperature, top_p, max_tokens)
            results.append(result)
    
    # åˆå¹¶ç»“æœ
    if len(results) > 1:
        markdown = "\n\n---\n\n".join([
            f"## Page {i + 1}\n\n{result}" 
            for i, result in enumerate(results)
        ])
    else:
        markdown = results[0]
    
    return images, markdown


def validate_file(file_path):
    """éªŒè¯æ–‡ä»¶"""
    if not file_path:
        return False, "è¯·ä¸Šä¼ æ–‡ä»¶"
    
    file_path = Path(file_path)
    
    if not file_path.exists():
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"
    
    if file_path.suffix.lower() not in config.ALLOWED_FILE_TYPES:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒï¼š{', '.join(config.ALLOWED_FILE_TYPES)}"
    
    size_mb = file_path.stat().st_size / (1024 * 1024)
    if size_mb > config.MAX_FILE_SIZE_MB:
        return False, f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{size_mb:.1f}MBï¼‰ï¼Œæœ€å¤§æ”¯æŒ {config.MAX_FILE_SIZE_MB}MB"
    
    return True, ""


def get_model_choices():
    """è·å–æ¨¡å‹é€‰æ‹©åˆ—è¡¨"""
    return [model["name"] for model in config.MODELS.values()]


def get_model_key_from_name(model_name):
    """ä»æ˜¾ç¤ºåç§°è·å–æ¨¡å‹é”®"""
    for key, model in config.MODELS.items():
        if model["name"] == model_name:
            return key
    return config.DEFAULT_MODEL


def test_model_connection(model_key):
    """æµ‹è¯•æ¨¡å‹ API è¿æ¥"""
    try:
        model_config = config.MODELS[model_key]
        client = OpenAI(
            api_key="dummy",
            base_url=model_config["api_base"],
            timeout=5.0
        )
        
        client.models.list()
        return True, f"âœ… {model_config['name']} è¿æ¥æ­£å¸¸"
    
    except Exception as e:
        return False, f"âŒ {model_config['name']} è¿æ¥å¤±è´¥: {str(e)}"